{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "218cc426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jerome/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jerome/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jerome/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk, random, json , pickle\n",
    "nltk.download('punkt');nltk.download('wordnet');nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import flatten\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a78300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "643b1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "class Training :\n",
    "    \n",
    "    def __init__(self):\n",
    "        dfile = open('intents.json').read()\n",
    "        self.intents=json.loads(dfile)['intents']\n",
    "        self.ignore=['!','@','#','$','%','^','&','*','?']\n",
    "        self.process_data()\n",
    "        \n",
    "    def process_data(self):\n",
    "        self.patterns=[]\n",
    "        \n",
    "        for i in self.intents:\n",
    "            temp=[]\n",
    "            if 'patterns' in i:\n",
    "                temp+=i['patterns']\n",
    "            self.patterns.append(temp) \n",
    "        \n",
    "        self.words=list(map(word_tokenize,flatten(self.patterns)))\n",
    "        self.classes= flatten( [[x[\"tag\"]]*len(y) for x,y in zip(self.intents,self.patterns)])\n",
    "        self.documents=list(map(lambda x,y:(x,y),self.words,self.classes))\n",
    "        self.words=list(map(lemma.lemmatize,self.words))\n",
    "        self.words=list(map(str.lower,flatten(self.words)))\n",
    "        self.words=list(filter(lambda x:x not in self.ignore_words,self.words))\n",
    "        self.words=list(map(lemmatizer.lemmatize,self.words))\n",
    "        self.words=sorted(list(set(self.words)))\n",
    "        self.classes=sorted(list(set(self.classes)))\n",
    "        \n",
    "    def train_data(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97c49733",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=list(map(lambda x:x[\"patterns\"],intents))\n",
    "words=list(map(word_tokenize,flatten(pattern)))\n",
    "classes= flatten( [[x[\"tag\"]]*len(y) for x,y in zip(intents,pattern)])\n",
    "documents=list(map(lambda x,y:(x,y),words,classes))\n",
    "words=list(map(str.lower,flatten(words)))\n",
    "ignore=['!','@','#','$','%','^','&','*','?']\n",
    "words=list(filter(lambda x:x not in ignore,words))\n",
    "words=list(map(lemma.lemmatize,words))\n",
    "words=sorted(list(set(words)))\n",
    "classes=sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde14cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
